{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "associate-shape",
   "metadata": {},
   "source": [
    "# Tarea Sesión 1: Estableciendo una línea base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-there",
   "metadata": {},
   "source": [
    "## Implementación\n",
    "\n",
    "### Paso 1: Cargando la librería y preparando los ficheros\n",
    "\n",
    "Cargamos la librería `pandas` y guardamos las rutas de los ficheros en sendas variables\n",
    "En `file` almacenaremos la ruta del fichero de entrenamiento, y en `fileEval` la del fichero de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proof-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = ('./train_en.tsv')\n",
    "\n",
    "fileEval = ('./dev_en.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-christopher",
   "metadata": {},
   "source": [
    "### Paso 2: Cargando los ficheros en dataframes\n",
    "\n",
    "Cargamos cada fichero en un dataframe, utilizando la función `read_csv()`, indicando la tabulación como caracter delimitador, y filtrando las columnas que queremos utilizar en cada uno.\n",
    "\n",
    "- En `data` almacenaremos los datos de entrenamiento, filtrando del fichero las columnas \"text\" y \"HS\".\n",
    "- En `evalEtiquetas` almacenamos las etiquetas de test, filtrando la columna \"HS\" del fichero de test\n",
    "- En `eval` almacenamos los datos de entrenamiento, filtrando la columna \"text\" del fichero de test\n",
    "\n",
    "\n",
    "Tras cargarlos, mostramos sus primeras filas con la función `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "composed-tongue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I swear I’m getting to places just in the nick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I’m an immigrant — and Trump is right on immig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#IllegalImmigrants #IllegalAliens #ElectoralSy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@DRUDGE_REPORT We have our own invasion issues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Worker Charged With Sexually Molesting Eight C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  I swear I’m getting to places just in the nick...\n",
       "1  I’m an immigrant — and Trump is right on immig...\n",
       "2  #IllegalImmigrants #IllegalAliens #ElectoralSy...\n",
       "3  @DRUDGE_REPORT We have our own invasion issues...\n",
       "4  Worker Charged With Sexually Molesting Eight C..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(file, delimiter='\\t', usecols =[\"text\",\"HS\"])\n",
    "\n",
    "evalEtiquetas = pd.read_csv(fileEval, delimiter='\\t', usecols =[\"HS\"])\n",
    "\n",
    "eval = pd.read_csv(fileEval, delimiter='\\t', usecols =[\"text\"])\n",
    "\n",
    "data.head()\n",
    "eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-forestry",
   "metadata": {},
   "source": [
    "### Paso 3: Realizando el preprocesamiento\n",
    "\n",
    "Antes de realizar el procesamiento, preparamos los datos para que sean procesables.\n",
    "Para ello, utilizaremos un idf, un estadístico que nos valora la relevancia de cada palabra dentro del texto\n",
    "\n",
    "#### Filtrando las etiquetas del conjunto a procesar\n",
    "\n",
    "Empezamos obteniendo las etiquetas del conjunto de datos. Para ello, en el dataframe de entrenamiento, filtramos la columna \"HS\"\n",
    "\n",
    "#### Creando la bolsa de palabras\n",
    "\n",
    "Utilizamos la librería SciKit Learn, con su clase `TfidfVectorizer` para crear una \"bolsa de palabras\", valorando la relevancia de cada palabra dentro del texto. Para ello, aplicamos las siguientes opciones:\n",
    "\n",
    "- La codificación del fichero será 'latin-1'\n",
    "- Las stopwords se descartarán según el diccionario indicado para el idioma inglés\n",
    "- Se descartarán las palabras que tengan menos de 5 apariciones (opción `min_df`)\n",
    "- Se aplicará una normalización de tipo 'l2', Esta norma indica que la suma de los cuadrados de los elementos del vector es 1, y que la similitud del coseno entre dos vectores es su producto elemento a elemento\n",
    "- Activamos el escalado basado en \"frecuencia de términos sublineal\" ([sublinear_tf](https://nlp.stanford.edu/IR-book/html/htmledition/sublinear-tf-scaling-1.html)). Este se basa en la premisa de que \"20 ocurrencias de una palabra no son 20 veces mas importantes que una sola ocurrencia\", dando una fórmula logarítmica para calcular la relevancia de un término. \n",
    "- Configuramos un rango de n-gramas de 1 a 3. \n",
    "\n",
    "El resultado lo almacenamos en el objeto `tfidf`. \n",
    "\n",
    "#### Realizando el aprendizaje\n",
    "\n",
    "Con la configuración ya establecida, llamamos a `fit_transform()`, pasándole por parámetro el conjunto de entrenamiento. Esta función aprenderá el vocabulario y el idf, y devolverá una matriz de documentos vs términos.\n",
    "\n",
    "Almacenamos la matriz en el objeto `features`\n",
    "\n",
    "#### Mostrando los datos\n",
    "\n",
    "Finalmente, visualizamos el tamaño de la matriz con el atributo `shape`, y su contenido en forma de vector con `toarray()`. Vemos que la matriz tiene 9000 filas y 4380 columnas. \n",
    "\n",
    "También mostramos el idf, que nos mostrará un valor de relevancia de cada palabra del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coordinate-spiritual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 4380)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[5.46070006 7.90786638 8.15918081 ... 8.15918081 6.84699442 8.15918081]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "labels = data.HS\n",
    "\n",
    "#print(labels)\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 3), stop_words='english')\n",
    "\n",
    "features = tfidf.fit_transform(data.text)\n",
    "\n",
    "print(features.shape)\n",
    "\n",
    "print(features.toarray())\n",
    "\n",
    "print(tfidf.idf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-today",
   "metadata": {},
   "source": [
    "### Paso 4: Dividiendo la colección en subconjuntos\n",
    "\n",
    "Para evitar problemas de sobreaprendizaje, en los que el clasificador se aprende su propio conjunto de ejemplos, dividimos el conjunto de datos en dos partes: entrenamiento y test. \n",
    "\n",
    "Como conjunto inicial, utilizaremos la matriz generada anteriormente, almacenada en `features`. \n",
    "\n",
    "Para dividir el conjunto, utilizaremos la función `train_test_split` de SciKit Learn. A esta le pasaremos el conjunto `features`, las etiquetas, y configuraremos varias opciones:\n",
    "\n",
    "- Los datos se particionarán según sus etiquetas (opción `stratify`)\n",
    "- Tamaño de los conjuntos de test: 20% del conjunto original\n",
    "- Semilla para generador aleatorio: 1234\n",
    "\n",
    "Esta función devolverá una tupla con los 4 subconjuntos generados: 2 de entrenamiento, y 2 de test. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "original-seating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8578    0\n",
      "5453    1\n",
      "5601    1\n",
      "4401    0\n",
      "2675    0\n",
      "       ..\n",
      "7954    0\n",
      "3453    1\n",
      "984     1\n",
      "7460    0\n",
      "6239    1\n",
      "Name: HS, Length: 7200, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# división del conjunto en entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels,\n",
    "\n",
    "                                                    stratify=labels,\n",
    "\n",
    "                                                    test_size=0.2,\n",
    "\n",
    "                                                    random_state=1234)\n",
    "\n",
    "#print(X_train)\n",
    "print(y_train)\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-investigation",
   "metadata": {},
   "source": [
    "### Paso 5: Creando el clasificador\n",
    "\n",
    "Una vez preparados los subconjuntos de entrenamiento y test, preparamos el clasificador.\n",
    "En este caso, probaremos 3 clasificadores diferentes: \n",
    "\n",
    "- *RandomForestClassifier*: basado en un bosque aleatorio. A este le aplicamos los siguientes parámetros:\n",
    "    \n",
    "    - `criterion`: Función de medición de la calidad de una partición. Admite dos valores: 'giny' o 'entropy'.\n",
    "        En este caso, elegimos este último\n",
    "    \n",
    "    - `n-estimators`: Número de árboles que conforman el bosque. Establecemos su valor a 100\n",
    "    - `class-weight`: Peso asociado a cada etiqueta. Establecemos un valor de 0.6 para la clase 1.\n",
    "    \n",
    "- *SVC*: basado en una Máquina Vector de Soporte. Aplicamos los siguientes parámetros:\n",
    "\n",
    "    - `kernel`: Tipo de kernel utilizado por el algoritmo. En nuestro caso, utilizaremos el tipo 'rbf'\n",
    "    - `gamma`: Coeficiente utilizado por el kernel. Lo establecemos a 0.001\n",
    "    - `C`: Parámetro de regularización. La anchura de regularización es inversamente proporcional a su valor. Lo establecemos a 300. \n",
    "    - `class_weight`: Establece el parámetro C de la clase 'i' a peso_clase[i]*c. En nuestro caso, establecemos el peso de la clase 0 a 0.7\n",
    "\n",
    "- *MLPClassifier*: basado en una red neuronal. En este caso, dejamos todos los parámetros a sus valores por defecto.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Creamos el objeto clasificador con uno de los tres anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "developmental-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#clasificador = RandomForestClassifier(criterion='entropy', n_estimators=100, class_weight={1: 0.6})\n",
    "\n",
    "#clasificador = svm.SVC(kernel='rbf', gamma=0.001, C=300, class_weight={0: 0.7})  \n",
    "\n",
    "clasificador = MLPClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-voltage",
   "metadata": {},
   "source": [
    "### Paso 6: Probando el clasificador con el conjunto de entrenamiento\n",
    "\n",
    "Con el clasificador seleccionado anteriormente, realizamos el ajuste del modelo sobre el conjunto de entrenamiento\n",
    "\n",
    "En primer lugar, llamamos al método `fit()` para realizar el ajuste al modelo, usando los conjuntos de entrenamiento. \n",
    "\n",
    "Posteriormente, llamamos a `predict()` para obtener las observaciones del conjunto de test X sin etiquetar. Las almacenamos en el objeto `pred_y`. \n",
    "\n",
    "Y, finalmente, mostramos la puntuación obtenida sobre los conjuntos de test.\n",
    "\n",
    "Esta es:\n",
    "\n",
    "- *MLPClassifier*: 0.713333\n",
    "- *SVC*: 0.806667\n",
    "- *RandomForestClassifier*: 0.796111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mathematical-surprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCR: 0.709444\n"
     ]
    }
   ],
   "source": [
    "clasificador.fit(X_train, y_train)\n",
    "\n",
    "pred_y = clasificador.predict(X_test)\n",
    "\n",
    "print(\"CCR: %f\"%(clasificador.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-elephant",
   "metadata": {},
   "source": [
    "### Paso 7: Observando los resultados\n",
    "\n",
    "Una vez realizado el procesamiento sobre los datos de entrenamiento, observamos los resultados\n",
    "\n",
    "#### Generando la matriz de confusión\n",
    "\n",
    "Empezamos generando la matriz de confusión. Esta nos asociará los datos y pronósticos a los fallos y aciertos\n",
    "Para ello llamamos a la función `confusion_matrix()`, pasándole los conjuntos de test y predicción de Y\n",
    "\n",
    "Los datos se mostrarán de la siguiente [forma](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html):\n",
    "\n",
    "- Posición (0,0): Verdaderos negativos (TN)\n",
    "- Posición (0,1): Falsos positivos (FP)\n",
    "- Posición (1,0): Falsos negativos (FN)\n",
    "- Posición (1,1): Verdaderos positivos (TP)\n",
    "\n",
    "Esta nos da los siguientes resultados para cada clasificador:\n",
    "    \n",
    "| Clasificador | TN (aciertos clase 0) | FP (fallos clase 1) | FN (fallos clase 0) | TP (aciertos clase 1) \n",
    "| -- | -- | -- | -- | --\n",
    "| RandomForestClassifier | 918 | 125 | 242 | 515\n",
    "| SVC | 830 | 205 | 143 | 614\n",
    "| MLPClassifier | 760 | 283 | 242 | 515\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "handy-found",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[838, 205],\n",
       "       [143, 614]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-desert",
   "metadata": {},
   "source": [
    "#### Generando el reporte de clasificación\n",
    "\n",
    "Además, generamos un reporte de clasificación con varias métricas conocidas: precisión, cobertura, medida-f...\n",
    "\n",
    "| Clasificador | Precisión clase 0 | Precisión clase 1 | Cobertura clase 0 | Cobertura clase 1 \n",
    "| -- | -- | -- | -- | -- |\n",
    "| RandomForestClassifier | 0,85 | 0,75 | 1043 | 757 |\n",
    "| SVN | 0,85 | 0,75 | 1043 | 757\n",
    "| MLPClassifier | 0,76 | 0,65 | 1043 | 757\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "brown-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1043\n",
      "           1       0.75      0.81      0.78       757\n",
      "\n",
      "    accuracy                           0.81      1800\n",
      "   macro avg       0.80      0.81      0.80      1800\n",
      "weighted avg       0.81      0.81      0.81      1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-problem",
   "metadata": {},
   "source": [
    "### Paso 7: Probando el clasificador con datos reales\n",
    "\n",
    "Una vez realizado el procesamiento sobre los datos de entrenamiento, probamos a ejecutarlo con el conjunto de evaluación\n",
    "\n",
    "Ejecutamos el clasificador y mostramos todas las métricas de evaluación.\n",
    "Esto nos da los siguientes resultados para cada clasificador:\n",
    "\n",
    "| Clasificador | TN (aciertos clase 0) | FP (fallos clase 1) | FN (fallos clase 0) | TP (aciertos clase 1) | Precisión clase 0 | Precisión clase 1 | Cobertura clase 0 | Cobertura clase 1 \n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "| RandomForestClassifier | 463 | 110 | 138 | 289 | 0,77 | 0,72 | 573 | 427\n",
    "| SVC | 319 | 194 | 76 | 351 | 0,83 | 0,84 | 573 | 427 \n",
    "| MLPClassifier | 395 | 178 | 139 | 288 | 0,74 | 0,62 | 573 | 427\n",
    "\n",
    "También mostramos la tabla de predicción del conjunto, con la clasificación dada a cada ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "casual-piece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4380)\n",
      "CCR: 0.683000\n",
      "[[395 178]\n",
      " [139 288]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       573\n",
      "           1       0.62      0.67      0.65       427\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.68      0.68      0.68      1000\n",
      "weighted avg       0.69      0.68      0.68      1000\n",
      "\n",
      "[0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
      " 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 0 0\n",
      " 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1\n",
      " 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0\n",
      " 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1\n",
      " 0 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1\n",
      " 1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1\n",
      " 0 1 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0\n",
      " 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1\n",
      " 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0\n",
      " 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 1\n",
      " 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0\n",
      " 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1\n",
      " 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0\n",
      " 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1\n",
      " 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
      " 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0\n",
      " 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 0 0 1 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1\n",
      " 1 0 0 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0\n",
      " 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "evalConTfidf = tfidf.transform(eval.text)\n",
    "\n",
    "print(evalConTfidf.shape)\n",
    "\n",
    "evalPredict = clasificador.predict(evalConTfidf)\n",
    "\n",
    "print(\"CCR: %f\"%(clasificador.score(evalConTfidf, evalEtiquetas)))\n",
    "\n",
    "print(confusion_matrix(evalEtiquetas, evalPredict))\n",
    "\n",
    "print(classification_report(evalEtiquetas, evalPredict))\n",
    "\n",
    "print(evalPredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-anxiety",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Tras analizar los 3 clasificadores (sin modificar sus parámetros por defecto), observamos que el que da mayor precisión es el SVC. Sin embargo, sus resultados están muy desequilibrados, con muchos mas fallos en la clase 0 que en la 1. Los aciertos se mantienen prácticamente similares en ambas clases.\n",
    "\n",
    "En los otros dos clasificadores, vemos valores de precisión similares. Aunque, en el MLP, vemos que la precisión de la clase 1 es 10 puntos menor que en la clase 0. En ambos se perciben notables desequilibrios en el número de aciertos, con muchos mas aciertos en la clase 0 que en la 1.\n",
    "\n",
    "Por esta razón, el clasificador mas recomendable sería el SVC, al ser el mas equilibrado en cuanto a aciertos, y con mayor precisión en ambas clases. Aunque se podría añadir una segunda revisión con el RandomForestClassifier para equilibrar la tasa de aciertos y de fallos en los casos donde el SVC da peores resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
